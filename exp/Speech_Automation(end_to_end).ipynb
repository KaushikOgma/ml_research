{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-eNoWpQuTfK",
        "outputId": "bdf62298-18ba-442f-ed78-85c95fcfb512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sounddevice\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Collecting playsound\n",
            "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.7.2)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice) (1.17.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: torch==2.4.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.4.1+cu121)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (2024.6.1)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.6)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.9.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai) (1.24.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice) (2.22)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.65.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.23.4)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.4)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1->torchaudio) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.1->torchaudio) (1.3.0)\n",
            "Downloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Building wheels for collected packages: playsound\n",
            "  Building wheel for playsound (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7020 sha256=e986d367148ffb2b38045c887d2aba9411471052eb490f3610be4ec371e2d98d\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/89/ed/2d643f4226fc8c7c9156fc28abd8051e2d2c0de37ae51ac45c\n",
            "Successfully built playsound\n",
            "Installing collected packages: playsound, sounddevice\n",
            "Successfully installed playsound-1.3.0 sounddevice-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install sounddevice transformers torchaudio scipy playsound google-generativeai soundfile pydub pygobject"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import torch\n",
        "import torchaudio\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline, AutoModelForTextToWaveform\n",
        "from scipy.io.wavfile import write as write_wav\n",
        "import google.generativeai as genai\n",
        "#Instead of playsound, use pydub's AudioSegment\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "import time\n",
        "from google.colab import files\n",
        "\n",
        "# Function to upload audio file\n",
        "def upload_audio():\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        print(f\"Uploaded file: {filename}\")\n",
        "        return filename\n",
        "\n",
        "# Load Whisper model\n",
        "def load_whisper_model(model_id=\"openai/whisper-large-v2\"):\n",
        "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "    print(f\"Running on {device.upper()}\")\n",
        "    model = AutoModelForSpeechSeq2Seq.from_pretrained(model_id, torch_dtype=torch_dtype)\n",
        "    processor = AutoProcessor.from_pretrained(model_id)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # Create a pipeline for speech recognition\n",
        "    return pipeline(\n",
        "        \"automatic-speech-recognition\",\n",
        "        model=model,\n",
        "        tokenizer=processor.tokenizer,\n",
        "        feature_extractor=processor.feature_extractor,\n",
        "        torch_dtype=torch_dtype,\n",
        "        device=device,\n",
        "    )\n",
        "\n",
        "# Speech-to-text conversion\n",
        "def speech_to_text(audio_file):\n",
        "    pipe = load_whisper_model()\n",
        "    with torch.no_grad():\n",
        "        result = pipe(audio_file)\n",
        "    return result[\"text\"]\n",
        "\n",
        "# Google Gemini API for grammar correction\n",
        "class GoogleGeminiAPI:\n",
        "    def __init__(self, api_key, model_name=\"models/gemini-1.0-pro-latest\"):\n",
        "        self.api_key = api_key\n",
        "        self.model_name = model_name\n",
        "        # Initialize the model attribute to None\n",
        "        self.model = None\n",
        "\n",
        "    def gcp_config(self):\n",
        "        genai.configure(api_key=self.api_key)\n",
        "\n",
        "    def load_model(self):\n",
        "        self.gcp_config()\n",
        "        self.model = genai.GenerativeModel(self.model_name)\n",
        "\n",
        "    def generate_text(self, prompt, text):\n",
        "        if not self.model:\n",
        "            self.load_model()\n",
        "        response = self.model.generate_content(prompt + text)\n",
        "        return response.text\n",
        "\n",
        "def correct_grammar(api_key, text):\n",
        "    prompt = '''You are a highly knowledgeable language teacher with in-depth expertise in multiple languages, including their grammar, pronunciation, and vocabulary. Your role is to teach language learners how to speak fluently and accurately in any language they choose...\n",
        "        '''\n",
        "    gemini_api = GoogleGeminiAPI(api_key)\n",
        "    return gemini_api.generate_text(prompt, text)\n",
        "\n",
        "# Text-to-speech conversion using Bark\n",
        "def text_to_speech_bark(text, output_file=\"speech.wav\", amplification_db=10):\n",
        "    # Load Bark model and processor\n",
        "    processor = AutoProcessor.from_pretrained(\"suno/bark\")\n",
        "    model = AutoModelForTextToWaveform.from_pretrained(\"suno/bark\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    inputs = processor(text, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        audio_array = model.generate(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"]).cpu().numpy().squeeze()\n",
        "\n",
        "    # Save generated audio to a file\n",
        "    write_wav(output_file, 24000, audio_array)\n",
        "\n",
        "    # Load the audio file with pydub\n",
        "    sound = AudioSegment.from_wav(output_file)\n",
        "\n",
        "    # Amplify the audio by a specified gain in dB\n",
        "    amplified_sound = sound.apply_gain(amplification_db)\n",
        "\n",
        "    # Play the amplified sound\n",
        "    play(amplified_sound)\n",
        "\n",
        "# Main process flow\n",
        "def main(api_key):\n",
        "    total_start_time = time.time()\n",
        "\n",
        "    # Step 1: Upload audio\n",
        "    print(\"Please upload your audio file (WAV format)\")\n",
        "    start_time = time.time()\n",
        "    audio_file = upload_audio()  # Upload the audio file\n",
        "    print(f\"Audio uploaded in {time.time() - start_time:.2f} seconds.\")\n",
        "\n",
        "    # Step 2: Convert uploaded audio to text\n",
        "    print(\"Converting speech to text...\")\n",
        "    start_time = time.time()\n",
        "    transcribed_text = speech_to_text(audio_file)\n",
        "    print(f\"Transcribed Text: {transcribed_text}\")\n",
        "    print(f\"Speech to text completed in {time.time() - start_time:.2f} seconds.\")\n",
        "\n",
        "    # Step 3: Correct grammar and pronunciation\n",
        "    print(\"Correcting grammar and pronunciation...\")\n",
        "    start_time = time.time()\n",
        "    corrected_text = correct_grammar(api_key, transcribed_text)\n",
        "    print(f\"Corrected Text: {corrected_text}\")\n",
        "    print(f\"Grammar correction completed in {time.time() - start_time:.2f} seconds.\")\n",
        "\n",
        "    # Step 4: Convert corrected text to speech\n",
        "    print(\"Converting corrected text to speech...\")\n",
        "    start_time = time.time()\n",
        "    output_audio_file = \"final_output.wav\"\n",
        "    text_to_speech_bark(corrected_text, output_file=output_audio_file)\n",
        "    print(f\"Final speech saved to {output_audio_file}\")\n",
        "    print(f\"Text to speech completed in {time.time() - start_time:.2f} seconds.\")\n",
        "\n",
        "    total_end_time = time.time()\n",
        "    print(f\"Total process completed in {total_end_time - total_start_time:.2f} seconds.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    api_key = \"AIzaSyBCW-TszvSeBUqHd2Ap7gpnjaVUG5BAlx0\"  # Replace with your Google Gemini API key\n",
        "    main(api_key)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "rutKlzNxu2W4",
        "outputId": "59e326b8-6d03-47ce-a2d3-6ffd692535d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your audio file (WAV format)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9ef632f6-e059-498c-9ce8-146a83d4c683\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9ef632f6-e059-498c-9ce8-146a83d4c683\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Recording (5).mp3 to Recording (5) (3).mp3\n",
            "Uploaded file: Recording (5) (3).mp3\n",
            "Audio uploaded in 12.58 seconds.\n",
            "Converting speech to text...\n",
            "Running on CUDA:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed Text:  Yesterday I go to the store to buy some vegetables and tomatoes.\n",
            "Speech to text completed in 32.36 seconds.\n",
            "Correcting grammar and pronunciation...\n",
            "Corrected Text: Yesterday I went to the store to buy some vegetables and tomatoes.\n",
            "\n",
            "**Explanation:**\n",
            "The verb \"go\" is in the present tense, so it should be changed to \"went\" to match the past tense of \"yesterday.\"\n",
            "Grammar correction completed in 4.79 seconds.\n",
            "Converting corrected text to speech...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/encodec/modeling_encodec.py:120: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final speech saved to final_output.wav\n",
            "Text to speech completed in 87.54 seconds.\n",
            "Total process completed in 137.27 seconds.\n"
          ]
        }
      ]
    }
  ]
}